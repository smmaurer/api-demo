{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data APIs\n",
    "\n",
    "**Sam Maurer // maurer@berkeley.edu // Oct. 3, 2016**\n",
    "\n",
    "This notebook provides a demonstration of data-access APIs that operate over the web.\n",
    "\n",
    "In Part 1, we'll load and parse data from an automated USGS feed of earthquakes. In Part 2, we'll add query parameters to the workflow, using the Google Maps Geolocation API as an example. In Part 3, we'll use authenticated APIs to access (public) Twitter data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Reading from an automated data feed\n",
    "\n",
    "### USGS real-time earthquake feeds\n",
    "\n",
    "This is an API for near-real-time data on earthquakes. Results are provided in JSON format over the web. No authentication is needed, and rather than accepting queries, the API has a separate endpoint for each permutation of the data that users might want.\n",
    "\n",
    "**API documentation:**  \n",
    "http://earthquake.usgs.gov/earthquakes/feed/v1.0/geojson.php\n",
    "\n",
    "**Sample API endpoint, for magnitude 4.5+ earthquakes in past day:**  \n",
    "http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_day.geojson  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use endpoint for magnitude 2.5+ quakes in past week\n",
    "endpoint_url = \"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_week.geojson\"\n",
    "\n",
    "# open a connection to the URL\n",
    "connection = urllib.urlopen(endpoint_url)\n",
    "\n",
    "# download the results\n",
    "results = connection.read()\n",
    "\n",
    "print results[:500]  # first 500 characters\n",
    "print type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the results are a string with JSON-formatted data inside\n",
    "\n",
    "# parse the string into a Python data structure\n",
    "data = json.loads(results)\n",
    "\n",
    "print data['features'][0]  # first item from the array called 'features'\n",
    "print type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull out the event descriptions\n",
    "\n",
    "for quake in data['features']:\n",
    "    print quake['properties']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull out magnitudes and depths into a pandas dataframe\n",
    "\n",
    "# first, set up a dictionary of empty arrays\n",
    "d = {'magnitude': [], 'depth': []}\n",
    "\n",
    "# loop through the earthquakes and pull out datapoints\n",
    "for quake in data['features']:\n",
    "    d['magnitude'].append(quake['properties']['mag'])\n",
    "    d['depth'].append(quake['geometry']['coordinates'][2])\n",
    "\n",
    "# then load it all into a dataframe\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the depth vs. magnitude\n",
    "\n",
    "df.plot(x='magnitude', y='depth', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save dataframe to disk\n",
    "\n",
    "df.to_csv('usgs_earthquake_data.csv')\n",
    "\n",
    "print 'file saved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read it back later\n",
    "\n",
    "new_df = pd.DataFrame.from_csv('usgs_earthquake_data.csv')\n",
    "\n",
    "print new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Querying an API endpoint\n",
    "\n",
    "### Google Maps Geocoding API\n",
    "\n",
    "Google Maps has several APIs for getting search results programmatically. This one looks up latitude-longidtude coordinates (and other place information) for street addresses, which is called geocoding. \n",
    "\n",
    "It works similarly to the earthquakes example, with query parameters added to the URL endpoint.\n",
    "\n",
    "**API documentation:**  \n",
    "https://developers.google.com/maps/documentation/geocoding/intro\n",
    "\n",
    "**API endpoint:**  \n",
    "https://maps.googleapis.com/maps/api/geocode/json\n",
    "\n",
    "**API endpoint with query parameters:**  \n",
    "https://maps.googleapis.com/maps/api/geocode/json?address=Wurster+Hall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we have to encode the search query so that it can be passed as a URL, \n",
    "# with spaces and other special characters removed\n",
    "\n",
    "endpoint = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
    "\n",
    "params = {\n",
    "    'address': 'Wurster Hall, Berkeley, CA',\n",
    "}\n",
    "\n",
    "url = endpoint + '?' + urllib.urlencode(params)\n",
    "print url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open a connection to the URL\n",
    "connection = urllib.urlopen(url)\n",
    "\n",
    "# download and parse the results\n",
    "results = json.loads(connection.read())\n",
    "\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull out the formatted addresses\n",
    "\n",
    "for item in results['results']:\n",
    "    print item['formatted_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Querying an API with authentication\n",
    "\n",
    "### Twitter REST and Streaming APIs\n",
    "\n",
    "Twitter's APIs also operate over the web, but they require a back-and-forth authentication process at the beginning of a connection. It's easier to have a Python library handle this than to create the query URLs ourselves.\n",
    "\n",
    "The REST APIs perform stand-alone operations: we submit a query and receive results, like in earlier examples. The Streaming API continues sending results in real time until we disconnect.\n",
    "\n",
    "(REST is a set of principles describing how data transactions should work over the web, while the actual communication protocol is called HTTP. Web pages work through HTTP and REST too, but the browser steps in to interpret and display the content for you.)\n",
    "\n",
    "**API documentation:**  \n",
    "https://dev.twitter.com/rest/public  \n",
    "https://dev.twitter.com/streaming/overview\n",
    "\n",
    "**Documentation for third-party Python \"wrapper\"**:  \n",
    "https://github.com/geduldig/TwitterAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import API credentials from keys.py file in the\n",
    "# same directory as this notebook\n",
    "\n",
    "from keys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up an API connection using credentials from the keys file\n",
    "\n",
    "api = TwitterAPI(consumer_key, consumer_secret, \n",
    "                 access_token, access_token_secret)\n",
    "\n",
    "print \"Connection is set up but not tested\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a simple data request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Most recent tweet from @GBoeing's timeline\n",
    "\n",
    "endpoint = 'statuses/user_timeline'\n",
    "params = {\n",
    "    'screen_name': 'gboeing', \n",
    "    'count': 1\n",
    "}\n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print tweet['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What other data is there?\n",
    "\n",
    "print tweet.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Contents of some additional fields...\n",
    "# Here are the definitions: https://dev.twitter.com/overview/api/tweets\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print \"Tweet      // \", tweet['text']\n",
    "    print \"Timestamp  // \", tweet['created_at']\n",
    "    print \"Retweets   // \", tweet['retweet_count']\n",
    "    print \"Favorites  // \", tweet['favorite_count']\n",
    "    print \"Geotag     // \", tweet['coordinates']\n",
    "    print \"Language   // \", tweet['lang']\n",
    "    print \"User       // \", tweet['user']['screen_name']\n",
    "    print \"Followers  // \", tweet['user']['followers_count']\n",
    "    print \"Profile    // \", tweet['user']['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other API endpoints allow different types of searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search for public tweets about #muni\n",
    "\n",
    "endpoint = 'search/tweets'\n",
    "params = {\n",
    "    'q': '#muni', \n",
    "    'count': 5\n",
    "}\n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print tweet['text'] + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search for public tweets in Hindi\n",
    "\n",
    "endpoint = 'search/tweets'\n",
    "params = {\n",
    "    'q': '*', \n",
    "    'lang': 'hi', \n",
    "    'count': 5\n",
    "} \n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print tweet['text'] + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search for public tweets geotagged near the UC Berkeley campus\n",
    "\n",
    "endpoint = 'search/tweets'\n",
    "params = {\n",
    "    'q': '*', \n",
    "    'geocode': '37.873,-122.260,0.5km', \n",
    "    'count': 5\n",
    "} \n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print tweet['text'] + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. Try some different search queries!\n",
    "2. Display some more data fields in addition to the tweet text\n",
    "3. Advanced: can you figure out how to use the API to *post* a tweet?\n",
    "\n",
    "Here's the search documentation: https://dev.twitter.com/rest/reference/get/search/tweets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming live tweets in real time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Twitter limits simultaneous connections to the streaming API,\n",
    "# so this part may not work using the demo API keys during class\n",
    "\n",
    "endpoint = 'statuses/filter'\n",
    "params = {'locations': '-180,-90,180,90'}\n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "# 'enumerate' lets us count tweets as we receive them\n",
    "\n",
    "for i, tweet in enumerate(r.get_iterator()):\n",
    "    print tweet['created_at']\n",
    "    print tweet['place']['full_name'] + ', ' + tweet['place']['country']\n",
    "    print tweet['text'] + '\\n'\n",
    "    if (i > 20): break\n",
    "\n",
    "r.close()  # close streaming connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading tweets into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first, save some tweets to an array instead of just printing them\n",
    "\n",
    "r = api.request(endpoint, params)\n",
    "tweets = []\n",
    "\n",
    "for i, tweet in enumerate(r.get_iterator()):\n",
    "    if (i >= 500): break\n",
    "    tweets.append(tweet)\n",
    "\n",
    "r.close()\n",
    "print len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the raw data is very messy though!\n",
    "\n",
    "print tweets[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we'll pull out some pieces into a dataframe\n",
    "\n",
    "# first, set up a dictionary of empty arrays\n",
    "d = {'place': [], 'latitude': [], 'longitude': []}\n",
    "\n",
    "for t in tweets:\n",
    "    try:\n",
    "        # first check whether the fields we want exist\n",
    "        _test = t['coordinates']['coordinates']\n",
    "        \n",
    "        # then pull out the data\n",
    "        d['place'].append(t['place']['name'])\n",
    "        d['latitude'].append(t['coordinates']['coordinates'][1])\n",
    "        d['longitude'].append(t['coordinates']['coordinates'][0])\n",
    "        \n",
    "    except:\n",
    "        # if the test failed, continue to next tweet\n",
    "        continue\n",
    "\n",
    "# load it into a dataframe\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.sort('place').head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(x='longitude', y='latitude', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note that when working with text strings that include characters from \n",
    "# other alphabets, you need to keep track of the text encoding.\n",
    "\n",
    "# Some interesting related reading:\n",
    "# - http://www.joelonsoftware.com/articles/Unicode.html\n",
    "\n",
    "df.to_csv('saved_coords.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise for the remainder of class\n",
    "\n",
    "Choose one:\n",
    "\n",
    "1. Using one of the APIs from this demo, save and graph a different aspect of the data.  \n",
    "   &nbsp;\n",
    "\n",
    "2. Or, search the web for another API that provides data you're interested in. Can you figure out how to connect to it using Python code?\n",
    "\n",
    "Some common terms for describing these APIs that operate over the web are \"HTTP\" and \"REST\". The most frequent data format they provide is JSON, but with some code modifications you can parse other formats as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
